Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2016-04-22 09:07:00.638378: step 0, loss = 37.09 (0.6 examples/sec; 102.272 sec/batch)
2016-04-22 09:14:52.026078: step 50, loss = 33.80 (7.4 examples/sec; 8.680 sec/batch)
2016-04-22 09:22:04.769034: step 100, loss = 32.48 (7.2 examples/sec; 8.849 sec/batch)
2016-04-22 09:29:57.244366: step 150, loss = 31.20 (7.8 examples/sec; 8.201 sec/batch)
2016-04-22 09:37:23.311288: step 200, loss = 29.98 (7.4 examples/sec; 8.693 sec/batch)
2016-04-22 09:44:56.107705: step 250, loss = 28.80 (7.1 examples/sec; 9.059 sec/batch)
2016-04-22 09:52:16.216627: step 300, loss = 27.67 (7.2 examples/sec; 8.872 sec/batch)
2016-04-22 09:59:52.331651: step 350, loss = 26.58 (7.5 examples/sec; 8.535 sec/batch)
2016-04-22 10:08:22.902789: step 400, loss = 25.54 (3.9 examples/sec; 16.464 sec/batch)
2016-04-22 10:17:52.268890: step 450, loss = 24.54 (5.8 examples/sec; 11.104 sec/batch)
2016-04-22 10:25:55.345222: step 500, loss = 23.58 (7.3 examples/sec; 8.740 sec/batch)
2016-04-22 10:33:42.033826: step 550, loss = 22.65 (7.5 examples/sec; 8.487 sec/batch)
2016-04-22 10:41:15.410905: step 600, loss = 21.76 (7.2 examples/sec; 8.922 sec/batch)
2016-04-22 10:48:59.933717: step 650, loss = 20.91 (6.8 examples/sec; 9.425 sec/batch)
2016-04-22 10:56:56.330213: step 700, loss = 20.09 (6.7 examples/sec; 9.566 sec/batch)
2016-04-22 11:04:48.332546: step 750, loss = 19.30 (7.1 examples/sec; 9.076 sec/batch)
2016-04-22 11:12:38.508747: step 800, loss = 18.55 (7.0 examples/sec; 9.104 sec/batch)
2016-04-22 11:20:29.215030: step 850, loss = 17.82 (7.1 examples/sec; 9.052 sec/batch)
2016-04-22 11:28:15.866854: step 900, loss = 17.12 (7.3 examples/sec; 8.759 sec/batch)
2016-04-22 11:35:50.509861: step 950, loss = 16.45 (7.3 examples/sec; 8.761 sec/batch)